
<!DOCTYPE html>
<html>

<head>


<link rel="stylesheet" href="style.css">


</head>


<body onload="refresh()">


<div class="topnav">
  <a href="..">Home</a>
  <a href="" class="active">Research</a>
  <a href="../cv">Curriculum Vitae</a>
  <a href="../coursework">Undergraduate Coursework</a>
  <a href="../other">Other</a>
  <h1> Research </h1>
</div>

<div class="gap"></div>
<div class="gap">
<p>
<u>Research Statement</u>
<br>
In the future, I want to further investigate <span style="font-weight:bold">deep learning </span>
from a statistical machine
learning perspective.  I want to better understand the
<span style="font-weight:bold">dynamics of training</span> with gradient descent on
deep networks as well as further investigate their <span style="font-weight:bold">representative power</span>
with particular architectures and specific datasets.
In particular, I want to assess the interplay between training and validating and how the assumptions
we originally make align with the studied regimes of neural networks.
  I believe these
questions are fundamental to every model we use, however, neural network's  incredible
functionality have distracted us from answering these fundamental questions.
<br>
</p>

<div class="gap"></div>
<br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-33723-0_14">
Hierarchical Semantic Labeling with Adaptive Confidence</a> (Computer Vision) (2019)
<br>
<img src="images/hierarchical_figure.PNG" alt="Figure of Main Idea"
height="181" width="462" style="margin-left:69px" border="2"></img>
<br>
<a href="https://arxiv.org/abs/1911.07426"> The Perfect Shuffle</a> (Combinatorics) (Summer 2019)
<br>
<a href="https://people.math.osu.edu/chmutov.1/wor-gr-su19/Rushil-Raghavan-MIGHTY_10192019.pdf">
Signed Symmetric Chromatic Polynomial</a> (Graph Theory) (Summer 2018)
<br>
</div>

</body>
</html>
